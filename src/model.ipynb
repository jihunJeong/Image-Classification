{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tropical-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-forth",
   "metadata": {},
   "source": [
    "## Lesson 5 - Model\n",
    " - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n",
    " - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n",
    "     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n",
    "     ```\n",
    "     Base class for all neural network modules.\n",
    "     Your models should also subclass this class.\n",
    "     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "congressional-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-blond",
   "metadata": {},
   "source": [
    "### 모델 디버깅\n",
    " - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-furniture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
      "          [-0.3121,  0.3171, -0.2744],\n",
      "          [-0.2630,  0.2822,  0.1777]]],\n",
      "\n",
      "\n",
      "        [[[-0.2105, -0.0697,  0.0058],\n",
      "          [-0.0030, -0.0819,  0.2346],\n",
      "          [ 0.2764, -0.2938, -0.1024]]],\n",
      "\n",
      "\n",
      "        [[[-0.2025,  0.1796,  0.2938],\n",
      "          [ 0.3048, -0.2732,  0.2842],\n",
      "          [-0.3299,  0.0659, -0.0495]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "conv1.bias           - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([-0.1888, -0.1223, -0.1941], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "bn1.weight           - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "bn1.bias             - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1148,  0.1610,  0.1144],\n",
      "          [-0.1461,  0.1109,  0.0340],\n",
      "          [ 0.1891, -0.1424, -0.1381]],\n",
      "\n",
      "         [[-0.1193, -0.1736, -0.0267],\n",
      "          [-0.0312, -0.0223, -0.0892],\n",
      "          [-0.1073,  0.0360, -0.0434]],\n",
      "\n",
      "         [[-0.1348, -0.1387,  0.1024],\n",
      "          [ 0.0397, -0.0577, -0.1530],\n",
      "          [-0.1001,  0.1715, -0.0153]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1722,  0.0517, -0.0629],\n",
      "          [ 0.1682,  0.0565,  0.1647],\n",
      "          [-0.0230, -0.1156, -0.1542]],\n",
      "\n",
      "         [[ 0.0370, -0.1518, -0.0013],\n",
      "          [-0.0431,  0.0341, -0.0335],\n",
      "          [-0.1219,  0.0302,  0.1259]],\n",
      "\n",
      "         [[-0.1327,  0.1287,  0.0202],\n",
      "          [-0.1142, -0.1443,  0.0142],\n",
      "          [-0.1572, -0.1501,  0.1459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721, -0.0297, -0.0048],\n",
      "          [-0.1838,  0.1055,  0.0106],\n",
      "          [ 0.1605, -0.0249,  0.1466]],\n",
      "\n",
      "         [[-0.0058,  0.0688, -0.1684],\n",
      "          [-0.0244, -0.0042,  0.1471],\n",
      "          [ 0.1722, -0.1729, -0.0693]],\n",
      "\n",
      "         [[-0.1367,  0.0289, -0.1668],\n",
      "          [-0.0907, -0.1705,  0.0901],\n",
      "          [-0.0084, -0.1194,  0.1117]]],\n",
      "\n",
      "\n",
      "        [[[-0.0076,  0.0846, -0.1553],\n",
      "          [ 0.1665,  0.1292,  0.0738],\n",
      "          [ 0.0451,  0.0048,  0.0185]],\n",
      "\n",
      "         [[-0.1773,  0.1831, -0.0103],\n",
      "          [ 0.1169,  0.1641, -0.0804],\n",
      "          [-0.0501, -0.0212, -0.1302]],\n",
      "\n",
      "         [[ 0.1438, -0.0782,  0.1319],\n",
      "          [-0.0802, -0.0071,  0.0556],\n",
      "          [-0.1689, -0.0469, -0.0840]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562, -0.0257, -0.0258],\n",
      "          [ 0.1155,  0.0083, -0.1232],\n",
      "          [-0.0255,  0.1090, -0.1705]],\n",
      "\n",
      "         [[ 0.1277, -0.0081, -0.1876],\n",
      "          [ 0.1439,  0.1627, -0.0208],\n",
      "          [-0.0896, -0.1187,  0.1468]],\n",
      "\n",
      "         [[ 0.0756, -0.0290,  0.0264],\n",
      "          [-0.1586,  0.0454,  0.0562],\n",
      "          [-0.0328, -0.1194, -0.0551]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. using named_parameters()\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"{param:20} - size: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-education",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
      "          [-0.3121,  0.3171, -0.2744],\n",
      "          [-0.2630,  0.2822,  0.1777]]],\n",
      "\n",
      "\n",
      "        [[[-0.2105, -0.0697,  0.0058],\n",
      "          [-0.0030, -0.0819,  0.2346],\n",
      "          [ 0.2764, -0.2938, -0.1024]]],\n",
      "\n",
      "\n",
      "        [[[-0.2025,  0.1796,  0.2938],\n",
      "          [ 0.3048, -0.2732,  0.2842],\n",
      "          [-0.3299,  0.0659, -0.0495]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1888, -0.1223, -0.1941], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 2. directly access with member variable\n",
    "print(model.conv1.weight)\n",
    "print(model.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-colon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-bloom",
   "metadata": {},
   "source": [
    "### 학습된 모델 저장하기\n",
    " - `torch.save(model.state_dict(), save_path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dangerous-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving success at ./runs/best.pth\n",
      "Saved models : ['best.pth']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_folder = \"./runs/\"\n",
    "save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
    "os.makedirs(save_folder, exist_ok=True)  \n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saving success at {save_path}\")\n",
    "print(f\"Saved models : {os.listdir(save_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-colorado",
   "metadata": {},
   "source": [
    "### 저장된 모델 불러오기\n",
    " - model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "possible-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading success from ./runs/best.pth\n"
     ]
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(save_path))\n",
    "print(f\"Model loading success from {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-organizer",
   "metadata": {},
   "source": [
    "#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unexpected-culture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter conv1.weight    from trained model and loaded model is equal? -> True\n",
      "parameter conv1.bias      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.weight      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.bias        from trained model and loaded model is equal? -> True\n",
      "parameter conv2.weight    from trained model and loaded model is equal? -> True\n"
     ]
    }
   ],
   "source": [
    "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
    "    is_equal = torch.equal(trained_weight, saved_weight)\n",
    "    print(f\"parameter {name:15} from trained model and loaded model is equal? -> {is_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-heritage",
   "metadata": {},
   "source": [
    "#### state_dict() 이 무엇인가요?\n",
    " - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n",
    " - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n",
    " - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n",
    "   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distant-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
      "tensor([[[[ 0.2264,  0.2768, -0.2716],\n",
      "          [-0.3121,  0.3171, -0.2744],\n",
      "          [-0.2630,  0.2822,  0.1777]]],\n",
      "\n",
      "\n",
      "        [[[-0.2105, -0.0697,  0.0058],\n",
      "          [-0.0030, -0.0819,  0.2346],\n",
      "          [ 0.2764, -0.2938, -0.1024]]],\n",
      "\n",
      "\n",
      "        [[[-0.2025,  0.1796,  0.2938],\n",
      "          [ 0.3048, -0.2732,  0.2842],\n",
      "          [-0.3299,  0.0659, -0.0495]]]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv1.bias           - size: torch.Size([3])\n",
      "tensor([-0.1888, -0.1223, -0.1941])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.weight           - size: torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.bias             - size: torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_mean     - size: torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_var      - size: torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.num_batches_tracked - size: torch.Size([])\n",
      "tensor(0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
      "tensor([[[[-0.1148,  0.1610,  0.1144],\n",
      "          [-0.1461,  0.1109,  0.0340],\n",
      "          [ 0.1891, -0.1424, -0.1381]],\n",
      "\n",
      "         [[-0.1193, -0.1736, -0.0267],\n",
      "          [-0.0312, -0.0223, -0.0892],\n",
      "          [-0.1073,  0.0360, -0.0434]],\n",
      "\n",
      "         [[-0.1348, -0.1387,  0.1024],\n",
      "          [ 0.0397, -0.0577, -0.1530],\n",
      "          [-0.1001,  0.1715, -0.0153]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1722,  0.0517, -0.0629],\n",
      "          [ 0.1682,  0.0565,  0.1647],\n",
      "          [-0.0230, -0.1156, -0.1542]],\n",
      "\n",
      "         [[ 0.0370, -0.1518, -0.0013],\n",
      "          [-0.0431,  0.0341, -0.0335],\n",
      "          [-0.1219,  0.0302,  0.1259]],\n",
      "\n",
      "         [[-0.1327,  0.1287,  0.0202],\n",
      "          [-0.1142, -0.1443,  0.0142],\n",
      "          [-0.1572, -0.1501,  0.1459]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721, -0.0297, -0.0048],\n",
      "          [-0.1838,  0.1055,  0.0106],\n",
      "          [ 0.1605, -0.0249,  0.1466]],\n",
      "\n",
      "         [[-0.0058,  0.0688, -0.1684],\n",
      "          [-0.0244, -0.0042,  0.1471],\n",
      "          [ 0.1722, -0.1729, -0.0693]],\n",
      "\n",
      "         [[-0.1367,  0.0289, -0.1668],\n",
      "          [-0.0907, -0.1705,  0.0901],\n",
      "          [-0.0084, -0.1194,  0.1117]]],\n",
      "\n",
      "\n",
      "        [[[-0.0076,  0.0846, -0.1553],\n",
      "          [ 0.1665,  0.1292,  0.0738],\n",
      "          [ 0.0451,  0.0048,  0.0185]],\n",
      "\n",
      "         [[-0.1773,  0.1831, -0.0103],\n",
      "          [ 0.1169,  0.1641, -0.0804],\n",
      "          [-0.0501, -0.0212, -0.1302]],\n",
      "\n",
      "         [[ 0.1438, -0.0782,  0.1319],\n",
      "          [-0.0802, -0.0071,  0.0556],\n",
      "          [-0.1689, -0.0469, -0.0840]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0562, -0.0257, -0.0258],\n",
      "          [ 0.1155,  0.0083, -0.1232],\n",
      "          [-0.0255,  0.1090, -0.1705]],\n",
      "\n",
      "         [[ 0.1277, -0.0081, -0.1876],\n",
      "          [ 0.1439,  0.1627, -0.0208],\n",
      "          [-0.0896, -0.1187,  0.1468]],\n",
      "\n",
      "         [[ 0.0756, -0.0290,  0.0264],\n",
      "          [-0.1586,  0.0454,  0.0562],\n",
      "          [-0.0328, -0.1194, -0.0551]]]])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param, weight in model.state_dict().items():\n",
    "    print(f\"{param:20} - size: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metric-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.state_dict() type is : <class 'collections.OrderedDict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "print(f\"model.state_dict() type is : {type(model.state_dict())}\")\n",
    "type(model.state_dict()) == OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-sunrise",
   "metadata": {},
   "source": [
    "#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n",
    " - `named_parameters()` : returns only parameters\n",
    " - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n",
    " \n",
    " [Reference](https://stackoverflow.com/a/54747245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "needed-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
      "\n",
      "['conv1.weight',\n",
      " 'conv1.bias',\n",
      " 'bn1.weight',\n",
      " 'bn1.bias',\n",
      " 'bn1.running_mean',\n",
      " 'bn1.running_var',\n",
      " 'bn1.num_batches_tracked',\n",
      " 'conv2.weight']\n"
     ]
    }
   ],
   "source": [
    "pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n",
    "print()\n",
    "pprint(list(model.state_dict().keys()))  # state_dict(): retuns both parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-satin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "timely-regression",
   "metadata": {},
   "source": [
    "### CPU vs GPU\n",
    " - DL 모델은 다양한 프로세서(CPU, GPU, TPU) 를 사용하여 학습을 할 수 있습니다.\n",
    " - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 명시적으로 지정해주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-usage",
   "metadata": {},
   "source": [
    "#### cpu()\n",
    "Moves all model parameters and buffers to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "minus-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-revision",
   "metadata": {},
   "source": [
    "#### cuda()\n",
    "Moves all model parameters and buffers to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "determined-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-tourist",
   "metadata": {},
   "source": [
    "#### to()\n",
    "Moves and/or casts the parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "everyday-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set model device to cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "\n",
      "Set model device to cuda\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_options = ['cpu', 'cuda']\n",
    "for device_option in device_options:\n",
    "    device = torch.device(device_option)\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Set model device to {device_option}\")\n",
    "    for weight in model.parameters():\n",
    "        print(f\"model device: {weight.device}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-speaking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "domestic-liberty",
   "metadata": {},
   "source": [
    "### forward\n",
    " - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n",
    " - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n",
    " - Defines the computation performed at every call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "parental-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 5, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0390, 0.0000, 0.2121, 0.0726, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0725, 0.0000, 0.0000, 0.0952, 0.0000, 0.0000],\n",
       "          [0.0870, 0.0000, 0.0000, 0.0000, 0.0000, 0.1270, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1993, 0.0000, 0.0000, 0.1471, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0545, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0925, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6296, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.5254, 0.0000, 0.4816, 0.0826, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.3775, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0105, 0.0000, 0.0000, 0.2696, 0.0000, 0.0000, 0.2483, 0.2245],\n",
       "          [0.0109, 0.2748, 0.0000, 0.0000, 0.0000, 0.0000, 0.0370, 0.1316],\n",
       "          [0.0000, 0.0781, 0.1305, 0.0000, 0.1002, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1832, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2209, 0.3112, 0.0000, 0.0000, 0.0000, 0.3638]],\n",
       "\n",
       "         [[0.0000, 0.0100, 0.1925, 0.1045, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2385, 0.0000, 0.1339],\n",
       "          [0.3723, 0.0000, 0.1013, 0.3390, 0.1659, 0.3321, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1181, 0.0000, 0.0000, 0.0000, 0.1191, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2855, 0.0000, 0.3361, 0.1483],\n",
       "          [0.0430, 0.0000, 0.0000, 0.3623, 0.0000, 0.0000, 0.0000, 0.0056],\n",
       "          [0.0000, 0.0000, 0.1388, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0441, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2263, 0.1820, 0.0000, 0.1551, 0.2266, 0.2684, 0.0000, 0.1696],\n",
       "          [0.0000, 0.1383, 0.0968, 0.1351, 0.1295, 0.0000, 0.0127, 0.0000],\n",
       "          [0.0000, 0.4200, 0.0000, 0.0000, 0.4015, 0.0000, 0.9178, 0.0000],\n",
       "          [0.1558, 0.5825, 0.0000, 0.6808, 0.2590, 0.2226, 0.2121, 0.1461],\n",
       "          [0.3494, 0.0000, 0.4411, 0.5046, 0.0000, 0.5198, 0.0000, 0.6452],\n",
       "          [0.3672, 0.0000, 0.3415, 0.0679, 0.0654, 0.3490, 0.0000, 0.7305],\n",
       "          [0.2146, 0.0000, 0.2010, 0.0209, 0.2788, 0.2414, 0.1299, 0.6389],\n",
       "          [0.2185, 0.0185, 0.3126, 0.0000, 0.3632, 0.0000, 0.5209, 0.0000]],\n",
       "\n",
       "         [[0.1142, 0.0000, 0.0000, 0.0000, 0.3630, 0.6166, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1071, 0.0000, 0.0000, 0.3197, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.4482, 0.0018, 0.0000, 0.0630, 0.7859, 0.0128],\n",
       "          [0.0764, 0.0000, 0.0000, 0.0313, 0.2572, 0.0000, 0.4272, 0.5330],\n",
       "          [0.4880, 0.0000, 0.0000, 0.1003, 0.0855, 0.0000, 0.0581, 0.2413],\n",
       "          [0.1568, 0.2851, 0.0000, 0.0000, 0.0873, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1688, 0.0000, 0.1646, 0.0000, 0.1115, 0.0000, 0.1221],\n",
       "          [0.0000, 0.0000, 0.4160, 0.0000, 0.0000, 0.0000, 0.2514, 0.0000]]]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 1, 12, 12).to(device)\n",
    "model.to(device)\n",
    "output = model(dummy_input)\n",
    "print(f\"model output: {output.size()}\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-reliance",
   "metadata": {},
   "source": [
    "#### Cautions\n",
    " - 모델과 인풋의 device 는 반드시 같아야 합니다.\n",
    " - 그렇지 않으면 (Runtime) Error 가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "realistic-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 5, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda')\n",
    "\n",
    "# device is same\n",
    "dummy_input = dummy_input.to(gpu_device)\n",
    "model.to(gpu_device)\n",
    "output = model(dummy_input)  # Fine \n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "welcome-medline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-52d7e79efd68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# raise Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model output: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5f680354f5ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(cpu_device)\n",
    "model.to(gpu_device)\n",
    "\n",
    "# device is different\n",
    "# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "output = model(dummy_input)  # raise Error\n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-stopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "crucial-affect",
   "metadata": {},
   "source": [
    "### requires_grad()\n",
    " - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n",
    " - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n",
    " - Change if autograd should record operations on parameters in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "arranged-budapest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> False\n",
      "param conv1.bias      required gradient? -> False\n",
      "param bn1.weight      required gradient? -> False\n",
      "param bn1.bias        required gradient? -> False\n",
      "param conv2.weight    required gradient? -> False\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = False\n",
    "model.requires_grad_(requires_grad=False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "downtown-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> True\n",
      "param conv1.bias      required gradient? -> True\n",
      "param bn1.weight      required gradient? -> True\n",
      "param bn1.bias        required gradient? -> True\n",
      "param conv2.weight    required gradient? -> True\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = True\n",
    "model.requires_grad_(requires_grad=True)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-mounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hearing-renaissance",
   "metadata": {},
   "source": [
    "### train(), eval()\n",
    " - 모델을 training(evaluation) 모드로 전환합니다.\n",
    " - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n",
    " - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n",
    " - [아래](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L111-L118)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n",
    " \n",
    "```\n",
    "if self.training and self.track_running_stats:\n",
    "    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n",
    "    if self.num_batches_tracked is not None:\n",
    "        self.num_batches_tracked = self.num_batches_tracked + 1\n",
    "        if self.momentum is None:  # use cumulative moving average\n",
    "            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
    "        else:  # use exponential moving average\n",
    "            exponential_average_factor = self.momentum\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "twenty-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: True\n"
     ]
    }
   ],
   "source": [
    "model.train()  # set model to train mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smaller-polish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: False\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set model to eval mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-newton",
   "metadata": {},
   "source": [
    "### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
