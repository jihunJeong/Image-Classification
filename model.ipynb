{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import print_function, division\r\n",
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from glob import glob\r\n",
    "\r\n",
    "import shutil\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\r\n",
    "from ipywidgets import IntProgress"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_dir = '/opt/ml/input/data/train/images'\r\n",
    "log_dir = '/opt/ml/code'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from torchvision.models import resnet18, resnet50, resnet101, detection\r\n",
    "from torch.optim import Adam, SGD\r\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n",
    "\r\n",
    "\r\n",
    "import torch.optim as optim\r\n",
    "from torch.optim import lr_scheduler\r\n",
    "import numpy as np\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets, models, transforms\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time\r\n",
    "import os\r\n",
    "import copy\r\n",
    "from sklearn.model_selection import StratifiedKFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Misc\r\n",
    "\r\n",
    "class AverageMeter(object):\r\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\r\n",
    "  def __init__(self):\r\n",
    "      self.reset()\r\n",
    "\r\n",
    "  def reset(self):\r\n",
    "    self.val = 0\r\n",
    "    self.avg = 0\r\n",
    "    self.sum = 0\r\n",
    "    self.count = 0\r\n",
    "\r\n",
    "  def update(self, val, n=1):\r\n",
    "    self.val = val\r\n",
    "    self.sum += val * n\r\n",
    "    self.count += n\r\n",
    "    self.avg = self.sum / self.count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Dataset\r\n",
    "import torch\r\n",
    "from torchvision import transforms\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from glob import glob\r\n",
    "\r\n",
    "class MaskDataset(Dataset):\r\n",
    "  def __init__(self, data_root, is_Train=True, input_size=224, transform=None):\r\n",
    "    super(MaskDataset, self).__init__()\r\n",
    "\r\n",
    "    self.img_list, self.labels= self._load_img_list(data_root, is_Train)\r\n",
    "    self.len = len(self.img_list)\r\n",
    "    self.input_size = input_size\r\n",
    "    self.transform = transform\r\n",
    "\r\n",
    "  def __getitem__(self, index):\r\n",
    "    img_path = self.img_list[index]\r\n",
    "    # Image Loading\r\n",
    "    img = Image.open(img_path)\r\n",
    "\r\n",
    "    if self.transform:\r\n",
    "      img = self.transform(img)\r\n",
    "\r\n",
    "    # Ground Truth\r\n",
    "    label = self._get_class_idx_from_img_name(img_path)\r\n",
    "    return img, label\r\n",
    "\r\n",
    "  def __len__(self):\r\n",
    "    return self.len\r\n",
    "\r\n",
    "  def _load_img_list(self, data_root, is_Train):\r\n",
    "    # Change the name of directory which has inconsistent naming rule.\r\n",
    "    full_img_list = glob(data_root + '/*')\r\n",
    "\r\n",
    "    for dir in full_img_list:\r\n",
    "      dirname = os.path.basename(dir)\r\n",
    "      if '-' in dirname:\r\n",
    "        shutil.move(dir, dir.replace(dirname, dirname.replace('-', '')))\r\n",
    "    \r\n",
    "    img_list = []\r\n",
    "    labels = []\r\n",
    "    for dir in glob(data_root + '/*'):\r\n",
    "      label = []\r\n",
    "      img_list.extend(glob(dir+'/*'))\r\n",
    "      for path in glob(dir+'/*'):\r\n",
    "          label.append(self._get_class_idx_from_img_name(path))\r\n",
    "      labels.extend(label)\r\n",
    "    return img_list, labels\r\n",
    "\r\n",
    "  def _load_img_ID(self, img_path):\r\n",
    "    return int(os.path.basename(img_path).split('_')[0])\r\n",
    "\r\n",
    "  def _get_class_idx_from_img_name(self, img_path):\r\n",
    "    img_name = os.path.basename(img_path)\r\n",
    "    dir = img_path.split('/')\r\n",
    "    img_info = dir[-2]\r\n",
    "    \r\n",
    "    label = [[[0,1,2],[3,4,5]],[[6,7,8], [9,10,11]],[[12,13,14],[15,16,17]]]\r\n",
    "    if 'normal' in img_name:\r\n",
    "        msk = 2\r\n",
    "    elif 'incorrect_mask' in img_name:\r\n",
    "        msk = 1\r\n",
    "    elif 'mask' in img_name :\r\n",
    "        msk = 0\r\n",
    "    \r\n",
    "    if 'female' in img_info:\r\n",
    "        gdr = 1\r\n",
    "    elif 'male' in img_info:\r\n",
    "        gdr = 0\r\n",
    "    \r\n",
    "    if int(img_info[-2:]) < 30:\r\n",
    "        age = 0\r\n",
    "    elif 30 <= int(img_info[-2:]) < 60:\r\n",
    "        age = 1\r\n",
    "    elif 60 <= int(img_info[-2:]):\r\n",
    "        age = 2\r\n",
    "\r\n",
    "    return label[msk][gdr][age]\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data_root = '/opt/ml/input/data/train/images'\r\n",
    "input_size = 224\r\n",
    "batch_size = 32\r\n",
    "lr = 1e-04\r\n",
    "EPOCHS=10\r\n",
    "\r\n",
    "# Dataset and Data Loader\r\n",
    "train_transform = transforms.Compose([\r\n",
    "    transforms.RandomCrop((330,220)),\r\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.2, saturation=0, hue=0),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize([0.560, 0.524, 0.501], [0.233, 0.243, 0.246])\r\n",
    "])\r\n",
    "\r\n",
    "valid_transform = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.CenterCrop(224),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize([0.560, 0.524, 0.501], [0.233, 0.243, 0.246])\r\n",
    "])\r\n",
    "\r\n",
    "dataset = MaskDataset(data_root, is_Train=True, input_size=input_size, transform=train_transform)\r\n",
    "labels = dataset.labels\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "device = torch.device('cuda')\r\n",
    "\r\n",
    "pretrained = True # True of False\r\n",
    "\r\n",
    "model = resnet50(pretrained)\r\n",
    "num_ftrs = model.fc.in_features\r\n",
    "model.fc = nn.Linear(num_ftrs, 18)\r\n",
    "\r\n",
    "model = model.to(device)\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = Adam(model.parameters(), lr=1e-04)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "k_folds = 5\r\n",
    "skfold = StratifiedKFold(n_splits=k_folds, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mtcnn\r\n",
    "from mtcnn.mtcnn import MTCNN\r\n",
    "\r\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\r\n",
    "\r\n",
    "def imgDetector(img_path,cascade,age_net,MODEL_MEAN_VALUES,age_list):    \r\n",
    "    image = Image.open(img_path)\r\n",
    "    image = image.convert('RGB')\r\n",
    "    pixels = np.asarray(image)\r\n",
    "    detector = MTCNN()\r\n",
    "    results = detector.detect_faces(pixels)\r\n",
    "    \r\n",
    "    x1, y1, w, h = results[0]['box']\r\n",
    "    x1, y1 = abs(x1), abs(y1)\r\n",
    "    x2, y2 = x1 + w, y1 + h\r\n",
    "    face = pixels[y1-10:y2+10, x1-10:x2+10]\r\n",
    "    blob = cv2.dnn.blobFromImage(face, 1, (227, 227), [104, 117, 123], True, False)\r\n",
    "\r\n",
    "    age_net.setInput(blob)\r\n",
    "    age_preds = age_net.forward()\r\n",
    "    age = age_preds.argmax()\r\n",
    "    info = age_list[age]\r\n",
    "    image = Image.fromarray(face)\r\n",
    "    face_array = np.asarray(image)\r\n",
    "    plt.imshow(face_array)\r\n",
    "    plt.show()\r\n",
    "    print(info)\r\n",
    "\r\n",
    "cascade_filename = 'haarcascade_frontalface_alt.xml'\r\n",
    "cascade = cv2.CascadeClassifier(cascade_filename)\r\n",
    "\r\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\r\n",
    "\r\n",
    "age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt','age_net.caffemodel')\r\n",
    "age_list = ['(0 ~ 2)','(4 ~ 6)','(8 ~ 12)','(15 ~ 20)', '(25 ~ 32)','(38 ~ 43)','(48 ~ 53)','(60 ~ 100)']\r\n",
    "\r\n",
    "print(dataset.img_list[9000])\r\n",
    "info = imgDetector(dataset.img_list[9000],cascade,age_net,MODEL_MEAN_VALUES,age_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Main\r\n",
    "print(\"Progress ...\", end=\"\", flush=True)\r\n",
    "os.makedirs(log_dir, exist_ok=True)\r\n",
    "\r\n",
    "with open(os.path.join(log_dir, 'train_log.csv'), 'w') as log:\r\n",
    "    for fold, (train_ids, valid_ids) in enumerate(skfold.split(dataset, labels)):                                                 \r\n",
    "        best_accuracy = 0\r\n",
    "        \r\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\r\n",
    "        valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_ids)\r\n",
    "        \r\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\r\n",
    "        valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_subsampler)\r\n",
    "        \r\n",
    "        model = resnet101(pretrained)\r\n",
    "        num_ftrs = model.fc.in_features\r\n",
    "        model.fc = nn.Linear(num_ftrs, 18)\r\n",
    "\r\n",
    "        model = model.to(device)\r\n",
    "\r\n",
    "        criterion = nn.CrossEntropyLoss()\r\n",
    "        optimizer = Adam(model.parameters(), lr=1e-04)\r\n",
    "        \r\n",
    "        for epoch in range(EPOCHS):\r\n",
    "            train_loss, valid_loss = AverageMeter(), AverageMeter()\r\n",
    "\r\n",
    "            correct = 0\r\n",
    "            total = 0\r\n",
    "            acc_train = 0\r\n",
    "            # Training\r\n",
    "            model.train()\r\n",
    "            for iter, (img, hm_gt) in enumerate(train_loader):\r\n",
    "              # optimizer에 저장된 미분값을 0으로 초기화\r\n",
    "              optimizer.zero_grad()\r\n",
    "              img, hm_gt = img.cuda(), hm_gt.cuda()\r\n",
    "              \r\n",
    "              # 모델에 이미지 forward\r\n",
    "              pred_logit = model(img)\r\n",
    "              # loss 값 계산\r\n",
    "              loss = 0\r\n",
    "              loss = criterion(pred_logit, hm_gt)\r\n",
    "\r\n",
    "              _, predicted = torch.max(pred_logit.data, 1)\r\n",
    "              correct += (predicted == hm_gt).sum().item()\r\n",
    "              total += img.size(0)\r\n",
    "              # Backpropagation\r\n",
    "              loss.backward()\r\n",
    "              optimizer.step()\r\n",
    "\r\n",
    "              # Log Update\r\n",
    "              train_loss.update(loss.item(), len(img))\r\n",
    "              print(\"\\rEpoch [%3d/%3d] | Iter [%3d/%3d] | Train Loss %.4f\" % (epoch+1, EPOCHS, iter+1, len(train_loader), train_loss.avg), end= '')\r\n",
    "            \r\n",
    "            acc_train = 100*(correct/total)\r\n",
    "            print(\" Accuracy %.2f\" % (acc_train))\r\n",
    "            # Validation\r\n",
    "            test_loss = 0\r\n",
    "            total = 0\r\n",
    "            correct = 0\r\n",
    "            accr_val = 0\r\n",
    "\r\n",
    "\r\n",
    "            model.eval()\r\n",
    "            for iter, (img, hm_gt) in enumerate(valid_loader):\r\n",
    "              img, hm_gt = img.cuda(), hm_gt.cuda()\r\n",
    "\r\n",
    "              # 모델에 이미지 forward (gradient 계산 X)\r\n",
    "              with torch.no_grad():\r\n",
    "                pred_logit = model(img)\r\n",
    "\r\n",
    "              _, predicted = torch.max(pred_logit.data,1)\r\n",
    "              correct += (predicted == hm_gt).sum().item()\r\n",
    "              total += img.size(0)\r\n",
    "\r\n",
    "              # loss 값 계산\r\n",
    "              loss = 0\r\n",
    "              loss = criterion(pred_logit, hm_gt)\r\n",
    "\r\n",
    "            # Log Update\r\n",
    "            valid_loss.update(loss.item(), len(img))\r\n",
    "            accr_val = (100* correct / total)\r\n",
    "            print(\"Epoch [%3d/%3d] | Valid Loss %.4f | Accuracy : %.2f\" % (epoch+1, EPOCHS, valid_loss.avg, accr_val))\r\n",
    "\r\n",
    "            # Log Writing\r\n",
    "            log.write('%d,%.4f,%.4f\\n'%(epoch, train_loss.avg, valid_loss.avg))\r\n",
    "            if accr_val > best_accuracy:\r\n",
    "                best_accuracy = accr_val\r\n",
    "                if not os.path.exists(log_dir):\r\n",
    "                    os.mkdir(log_dir)\r\n",
    "                print(f\"Model saved : acc - {accr_val}\")\r\n",
    "\r\n",
    "                torch.save(model, f'{log_dir}/model{fold}.pt')  \r\n",
    "                torch.save(model.state_dict(), \r\n",
    "                           f'{log_dir}/model_state_dict{fold}.pt')  \r\n",
    "                torch.save({\r\n",
    "                        'model': model.state_dict(),\r\n",
    "                        'optimizer': optimizer.state_dict()\r\n",
    "                    }, f'{log_dir}/all{fold}.tar')\r\n",
    "\r\n",
    "print(\"Done\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "test_dir = '/opt/ml/input/data/eval'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class TestDataset(Dataset):\r\n",
    "    def __init__(self, img_paths, transform):\r\n",
    "        self.img_paths = img_paths\r\n",
    "        self.transform = transform\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        image = Image.open(self.img_paths[index])\r\n",
    "\r\n",
    "        if self.transform:\r\n",
    "            image = self.transform(image)\r\n",
    "        return image\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\r\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\r\n",
    "image_dir = os.path.join(test_dir, 'images')\r\n",
    "\r\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\r\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\r\n",
    "transform = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.CenterCrop(224),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize([0.560, 0.524, 0.501], [0.233, 0.243, 0.246])\r\n",
    "])\r\n",
    "\r\n",
    "dataset = TestDataset(image_paths, transform)\r\n",
    "\r\n",
    "loader = DataLoader(\r\n",
    "    dataset,\r\n",
    "    shuffle=False\r\n",
    ")\r\n",
    "\r\n",
    "device = torch.device('cuda')\r\n",
    "oof_pred = None\r\n",
    "for idx in range(5):\r\n",
    "    model = torch.load(f'{log_dir}/model{idx}.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\r\n",
    "    model.load_state_dict(torch.load(f'{log_dir}/model_state_dict{idx}.pt'))  # state_dict를 불러 온 후, 모델에 저장\r\n",
    "\r\n",
    "    checkpoint = torch.load(f'{log_dir}/all{idx}.tar')   # dict 불러오기\r\n",
    "    model.load_state_dict(checkpoint['model'])\r\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    # 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\r\n",
    "    all_predictions = []\r\n",
    "    predictions = [0]*18\r\n",
    "    for images in loader:\r\n",
    "        with torch.no_grad():\r\n",
    "            images = images.to(device)\r\n",
    "            pred = model(images)\r\n",
    "            pred = pred.argmax(dim=-1)\r\n",
    "            all_predictions.extend(pred.cpu().numpy())\r\n",
    "    fold_pred = np.array(all_predictions)\r\n",
    "    print(fold_pred)\r\n",
    "    if oof_pred is None:\r\n",
    "        oof_pred = fold_pred / 5\r\n",
    "    else :\r\n",
    "        oof_pred += fold_pred / 5\r\n",
    "    \r\n",
    "submission['ans'] = np.argmax(oof_pred, axis=1)\r\n",
    "# 제출할 파일을 저장합니다.\r\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\r\n",
    "print('test inference is done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}